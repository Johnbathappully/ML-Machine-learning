{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Customer Flight Satisfaction Prediction & Pipeline Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Pandas, Numpy, pyplot and seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Not always recommended, but jsut so our notebook looks clean for this activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import the dataframes that are needed\n",
    "- Import \"Flight data_Train.csv\" and \"Surveydata_Train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/Flight_data.csv\")   # Read the data regarding customer attributes\n",
    "df2 = pd.read_csv(\"data/Survey_data.csv\")   # Feedback data from customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Join the two dataframes using the 'id' column as the primary key\n",
    "- Rename the Id column of one dataframe so that there \"id\" column name becomes same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using pandas' Join method\n",
    "#c = a.join(b)  # Joining two dfs on the 'Id' column\n",
    "\n",
    "df = df2.set_index(\"Id\").join(df1.set_index(\"ID\"))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()  # the combined dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Print the number of missing values in each of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() # Since True is 1 and False is 0, if you do a sum of a boolean dataframe, we get the number of trues in each col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also find it using the snippet below\n",
    "df.isnull().apply(pd.value_counts)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Drop all the rows having atleast one missing values and check the shape of the dataframe before and after dropping the rows\n",
    "- Fill null values in ArrivalDelayin_Mins with mean\n",
    "- After that drop all the rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a few columns where out of the total ~90k records, ~8k have missing value. Imputing them with a central tendency\n",
    "# might add undesirable noise in the data. Hence, lets tackle only the columns that have less missing values.\n",
    "\n",
    "# But before imputation let us check the distribution of the data. If there are outliers, we would prefer to impute with median\n",
    "# else mean can be good option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df['ArrivalDelayin_Mins']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above two analysis suggest that we are in for many outliers\n",
    "# so let us use the median to impute the values\n",
    "\n",
    "df.ArrivalDelayin_Mins.fillna(df.ArrivalDelayin_Mins.median(), inplace = True)\n",
    "\n",
    "# Alternate way - You can use the simpleimputer function of the sklearn.impute. You can try it out!\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean') \n",
    "# df['ArrivalDelayin_Mins'] = imputer.fit_transform(df['ArrivalDelayin_Mins'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rest other missing values are filled with not_captured.\n",
    "#It can be done in other way also or also can be dropped according to the problem and business context.\n",
    "df.dropna(inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Print correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df.corr() # It will show correlation of only numerical variables here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cor,annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is just one obvious correlation that we can see that is between arrival delay and departure delay. We can drop one of the variables here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['DepartureDelayin_Mins']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback columns\n",
    "Seat_comfort', 'Departure.Arrival.time_convenient', 'Food_drink', 'Gate_location',\n",
    "'Inflightwifi_service', 'Inflight_entertainment', 'Online_support',\n",
    "'Ease_of_Onlinebooking', 'Onboard_service', 'Leg_room_service',\n",
    "'Baggage_handling', 'Checkin_service', 'Cleanliness', 'Online_boarding'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Manually encode these variables(printed above) such that they follow an order based on the meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Departure.Arrival.time_convenient'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gate_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual label encoding\n",
    "df.replace({'extremely poor' : 0, 'poor' : 1, 'need improvement' : 2, 'acceptable' : 3, \n",
    "            'good' : 4, 'excellent' : 5}, inplace = True)  \n",
    "\n",
    "df.replace({'very inconvinient' : 0, 'Inconvinient' : 1, 'need improvement' : 2, 'manageable' : 3,\n",
    "            'Convinient' : 4, 'very convinient' : 5}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for encodings\n",
    "df['Departure.Arrival.time_convenient'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Display countplot of every feedback attribute with respect to Customer Satisfaction. \n",
    "\n",
    "You can use sns.countplot and set hue  = 'Satisfaction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can use seaborn's countplot to plot a stacked baatchart\n",
    "sns.countplot(df.Seat_comfort, hue = df.Satisfaction) \n",
    "plt.legend(loc = 'upper right', bbox_to_anchor=(1.45, 1)); # to place the legend in a 'good' position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are a lot of columns that we want to plot, we can put all of them in one plot by using subplot()\n",
    "# Additionally, since there are a lot of subplots that need to be plotted, we can use a for loop\n",
    "\n",
    "plt.figure(figsize= (30,20))  # setting the figure size\n",
    "pos = 1  # we will use this variable to index each of the plots\n",
    "feedback = [ 'Seat_comfort', 'Departure.Arrival.time_convenient', 'Food_drink',\n",
    "           'Gate_location', 'Inflightwifi_service','Inflight_entertainment',\n",
    "           'Online_support', 'Ease_of_Onlinebooking', 'Onboard_service',\n",
    "           'Leg_room_service', 'Baggage_handling','Checkin_service', 'Cleanliness', 'Online_boarding']\n",
    "\n",
    "for i in feedback:\n",
    "    plt.subplot(3, 5, pos)\n",
    "    sns.countplot(df[i], hue = df.Satisfaction,\n",
    "                  palette = {'satisfied':'green','neutral or dissatisfied': 'red'})\n",
    "    plt.legend().remove();  # Remove legend to make the entire plot look 'good'\n",
    "    pos += 1  # to plot over the grid one by one   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate way\n",
    "# Using sns.barplot()\n",
    "\n",
    "plt.figure(figsize= (30,20))  \n",
    "pos = 1  \n",
    "\n",
    "for i in feedback:\n",
    "    ct = pd.crosstab(df[i], df.Satisfaction)  # Crosstab \n",
    "    stacked =ct.stack().reset_index().rename(columns={0:'value'}) #dataframe with name and count accross satisfaction levels\n",
    "    plt.subplot(3, 5, pos)\n",
    "    sns.barplot(x=stacked[i], y=stacked.value, hue=stacked.Satisfaction,\n",
    "               palette = {'satisfied':'lightgreen','neutral or dissatisfied': 'coral'}) # Barplot\n",
    "    plt.legend().remove();  # Remove legend to make the entire plot look 'good'\n",
    "    pos += 1  # to plot over the grid one by one    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Draw all the insights that you can from the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Green and orange bars are counts of satisfied and dissatisfied customers respectively. We want to look for areas where there is a visually significant difference between the length of the stacked bars**\n",
    "\n",
    "- From the plots above,\n",
    "    - Seating comfort can cause high levels of satisfaction to customers. Hardly any people who rated highly for seat_comfort were dissatisfied\n",
    "    - A similar case with respect to inflight_entertainment. In this case, having less entertainment seems to have caused far more dissatisfaction compared to bad seating.\n",
    "    - Difference is observed in ease_of_online_booking quiet evidently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Print the average feedback score\n",
    "- When Satisfaction columns equals 'satisfied'\n",
    "- When Satisfaction columns is not equal to 'satisfied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feedback_cols = ['Seat_comfort', 'Departure.Arrival.time_convenient',\n",
    "                 'Food_drink', 'Gate_location', 'Inflightwifi_service',\n",
    "                 'Inflight_entertainment', 'Online_support', 'Ease_of_Onlinebooking', \n",
    "                 'Onboard_service', 'Leg_room_service', 'Baggage_handling', 'Checkin_service',\n",
    "                 'Cleanliness', 'Online_boarding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Satisfaction').mean() # Average rating of individual feedback attributes across satisfaction levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Draw any insights that you can from the above values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observe the Exreme values (lower side for 'dissatisfaction' and higher side for 'satisfaction')\n",
    "- Bad seats are a strong cause for customer dissatisfication\n",
    "- Time convenience doesn't seem to be that big of a deal\n",
    "- Dissatisfied customers had some bad experiences with food but average food seems to satisfy most people\n",
    "- Gate location is totally irrelevant\n",
    "- Wifi is quiet a factor. On an average, having good wifi yeilded customer satisfaction\n",
    "- Easy online booking facility seems to be very important for customer satisfaction\n",
    "- In flight entertainment seems to be a deal breaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Create a new column which is the mean of 'Ease_of_Onlinebooking', 'Online_boarding', 'Online_support' and name it \"avg_feedback_of_online_services\". \n",
    "\n",
    "DIY : If online services has a bad ratings then what is the average ratings of other feedback attributes? \n",
    "And how does it impact Final Satisfaction of customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_df = df.loc[:, ['Ease_of_Onlinebooking', 'Online_boarding', 'Online_support']]\n",
    "online_df['avg_feedback_of_online_services'] = online_df.mean(axis = 1)\n",
    "\n",
    "online_df['avg_feedback_of_online_services'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Encode the columns \"Gender\", \"CustomerType\", \"TypeTravel\", \"Class\", \"Satisfaction\" \n",
    "- Use manual encoding or other type of encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes in each of the categorical attributes\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'O':\n",
    "        print(i, '->', len(df[i].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manuanl Encoding\n",
    "df.replace({'Loyal Customer' : 1, 'disloyal Customer' : 0,\n",
    "               'Business travel' : 1, 'Personal Travel' : 0,\n",
    "              'Female' : 0, 'Male' : 1,\n",
    "               'satisfied':1, 'neutral or dissatisfied':0,'Eco':0,'Eco Plus': 1,'Business':2}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencoding\n",
    "df_coded = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_coded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MinMax Scaling - scales the data set such that all feature values are in the range [0, 1].\n",
    "* StandardScaler - removes the mean and scales the data to unit variance\n",
    "\n",
    "\n",
    "You can learn about other scalers here -\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_coded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are going to use StandardScaler to scale our data.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#What all columns to scale? I have preferred all columns except onehotencoded columns and target columns as\n",
    "#scaling of target feature will not change anything as they already have values like 0 and 1 only.\n",
    "#You may only scale numerical features and leave categorical features as required according to business problem need and results.\n",
    "cols_to_scale = ['Seat_comfort', 'Departure.Arrival.time_convenient',\n",
    "       'Food_drink', 'Gate_location', 'Inflightwifi_service',\n",
    "       'Inflight_entertainment', 'Online_support', 'Ease_of_Onlinebooking',\n",
    "       'Onboard_service', 'Leg_room_service', 'Baggage_handling',\n",
    "       'Checkin_service', 'Cleanliness', 'Online_boarding',\n",
    "       'Age', 'Flight_Distance','DepartureDelayin_Mins', 'ArrivalDelayin_Mins']\n",
    "\n",
    "df_coded[cols_to_scale] = scaler.fit_transform(df_coded[cols_to_scale].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_coded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_coded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Seperate the column \"Satisfaction\" from the rest of the columns\n",
    "- Create X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to drop highly correlated feature which we have found before as there features might affect our models.\n",
    "to_drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns= ['Satisfaction', 'DepartureDelayin_Mins'])  # Seperating the target and the rest\n",
    "#X = df.drop(columns= ['Satisfaction'])\n",
    "y = df.Satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Create train and test datasets\n",
    "- Use train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Splitting the data for training and testing out model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 1, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Print accuracy\n",
    "- Print accuracy on test data using below models\n",
    "- Logistic regression model trained using all the attributes\n",
    "- Logistic regression model trained using only the feedback columns\n",
    "- Decision tree model trained using all the attributes\n",
    "- Random forest model trained using all the attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression with only feedback columns\n",
    "from sklearn.linear_model import LogisticRegression #importing logistic regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)  # Predictions from logistic regression\n",
    "score1 = lr.score(X_test, y_test)\n",
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting customer satisfaction solely based on the feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression with only feedback columns\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.loc[:,feedback], y, random_state = 1, stratify = y)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "score2 = lr.score(X_test, y_test)\n",
    "\n",
    "print(f'Number of features used = {len(X_train.columns)}')\n",
    "print(f'Accuracy in predicting customer satisfaction solely based on the feedback = {score2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "score3 = dt.score(X_test, y_test)\n",
    "pred = dt.predict(X_test)\n",
    "\n",
    "print(f\"Decision tree acccuracy score: {score3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "score4 = rf.score(X_test, y_test)\n",
    "\n",
    "print(f'Random Forest accuracy score = {score4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Print feature importance\n",
    "- Print feature importance of Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree \n",
    "pd.Series(dt.feature_importances_, X_train.columns ).sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "pd.Series(rf.feature_importances_, X_train.columns).sort_values(ascending= False)\n",
    "## Alternate Way\n",
    "##pd.DataFrame({'Attribute': X_train.columns, 'Importance': rf.feature_importances_}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Print cross validation score\n",
    "- Decision tree model trained using all the attributes\n",
    "- Random Forest model trained using all the attributes\n",
    "- Fine tuned (using Grid Search or Random Search) Random Forest model\n",
    "\n",
    "**Display all the scores above with their respective models in a single dataframe**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#For Decision Tree dt\n",
    "scores = cross_val_score(dt, X, y, cv = 10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score5=scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Cross validation score of Decision tree = {score5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest rf\n",
    "score6 = cross_val_score(rf, X, y, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score6=score6.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Cross validation score of RF = {score6.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Tuning Using GridDSearch\n",
    "\n",
    "Doing it only for RandomForest as the mean CV score is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'bootstrap': [True],\n",
    " 'max_depth': [10, 20, 30, 40, 50],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4, 8],\n",
    " 'n_estimators': [100]}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), parameters, cv = 5, verbose = 2, n_jobs= 4)\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.best_params_\n",
    "\n",
    "\n",
    "# Best parameters\n",
    "#{'bootstrap': True,\n",
    "# 'max_depth': 30,\n",
    "# 'max_features': 'sqrt',\n",
    "# 'min_samples_leaf': 1,\n",
    "#  'n_estimators': 100} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap= True,\n",
    " max_depth= 20,\n",
    " max_features= 'sqrt',\n",
    " min_samples_leaf= 1,\n",
    " n_estimators= 100)\n",
    "\n",
    "score7 = cross_val_score(rf, X, y, cv = 5).mean()\n",
    "score7    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Technique' : ['Logistic Regression', \"LR with only feedback columns \", 'Decision tree',\n",
    "                       'Random forest', 'DT CV','RF CV','Tuned RF CV'],\n",
    "       'Score' : [score1, score2, score3, score4, score5, score6, score7] }\n",
    "\n",
    "result = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline - Automate and Simplify the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pipeline.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from category_encoders import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Age', 'Flight_Distance', 'DepartureDelayin_Mins']\n",
    "\n",
    "feedback_features = ['Seat_comfort', 'Departure.Arrival.time_convenient', 'Food_drink',\n",
    "       'Gate_location', 'Inflightwifi_service', 'Inflight_entertainment',\n",
    "       'Online_support', 'Ease_of_Onlinebooking', 'Onboard_service',\n",
    "       'Leg_room_service', 'Baggage_handling', 'Checkin_service',\n",
    "       'Cleanliness', 'Online_boarding']\n",
    "\n",
    "other_cat_cols =  ['Gender', 'CustomerType', 'TypeTravel', 'Class']\n",
    "\n",
    "\n",
    "#TRANSFORMERS\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "feedback_feature_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not_captured')),\n",
    "    ('label_encoder', OrdinalEncoder()),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "other_cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='not_captured')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('feed_col', feedback_feature_transformer, feedback_features),\n",
    "        ('other_cat_col', other_cat_transformer, other_cat_cols )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding into Pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(bootstrap= True,max_depth= 20,max_features= 'sqrt',min_samples_leaf= 1,n_estimators= 100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the raw data\n",
    "data = df2.set_index(\"Id\").join(df1.set_index(\"ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting X and y\n",
    "X_pipe = data.drop(['Satisfaction', 'ArrivalDelayin_Mins'], axis = 1)\n",
    "y_pipe = data['Satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data SPlit\n",
    "X_trains, X_tests, y_trains, y_tests = train_test_split(X_pipe,y_pipe, stratify = y_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Pipeline \n",
    "clf.fit(X_trains, y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting score \n",
    "clf.score(X_tests, y_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
