{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: \n",
    "The classification goal is to predict the likelihood of a liability customer buying personal loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.) Import the datasets and libraries, check datatype, statistical summary,shape,null values or incorrect imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lCWwBb-NgG-"
   },
   "outputs": [],
   "source": [
    "## importing libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xP18oduDNgHB",
    "outputId": "b69d694d-b81f-4ef4-8fea-36a6e7b65835"
   },
   "outputs": [],
   "source": [
    "# importing data\n",
    "\n",
    "df = pd.read_csv(\"Axe_Bank_Personal_Loan_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dh2IxnHgNgHG",
    "outputId": "84b75141-53fe-477a-8714-56d639d239a2"
   },
   "outputs": [],
   "source": [
    "df.info()        ## this would give datatype of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWOlgHZYNgHI",
    "outputId": "edb369d6-5d52-4f2a-d922-5d5bad471401",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aMddk8hxNgHL",
    "outputId": "b0f8172e-d422-47ca-8c22-7de98598bfc0"
   },
   "outputs": [],
   "source": [
    "#There are negative numbmers in experience! maybe typing error. \n",
    "# Convert to non-negative using .abs function\n",
    "\n",
    "df['Experience'] = df['Experience'].abs()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()  #check for null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of unique in each column?\n",
    "* Number of people with zero mortgage?\n",
    "* Number of people with zero credit card spending per month?\n",
    "* Value counts of all categorical columns.\n",
    "* Univariate and Bivariate\n",
    "* Get data model ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()\n",
    "# gives number of unique values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ID','ZIP Code'],axis=1,inplace=True)\n",
    "\n",
    "# dropping 'ID' column as it all the unique value and this column wont provide any insight to build a model\n",
    "# Zip Code represents region and region wise distribution of customers is not helping here\n",
    "# as alot region are there in just 5000 customers, therefore dropping 'ZIP Code'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Value Counts for Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGiFmmezNgHU"
   },
   "outputs": [],
   "source": [
    "vc = df[['Personal Loan', 'Securities Account', 'CD Account',\n",
    "       'Online', 'CreditCard']].sum().reset_index().rename(columns={'index':'Col_Name',0:\"Value_Count_1\"})\n",
    "vc['Value_Count_0'] = df.shape[0] - vc['Value_Count_1']\n",
    "vc\n",
    "\n",
    "# Value counts of all the category column with two unique values (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc['Value_Count_0']=(vc['Value_Count_0']*100)/5000\n",
    "vc['Value_Count_1']=(vc['Value_Count_1']*100)/5000\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Mortgage']==0].shape[0]\n",
    "\n",
    "#count of people having home mortgage as zero, Most of the people donot have mortgage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['Personal Loan'], df['CreditCard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "143/(1327+143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Personal Loan'], df['CreditCard'],normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`When CreditCard value is 0 or 1 in both cases the distribution of target variable is same therefore dropping CreditCard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('CreditCard',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Personal Loan'], df['Education'],normalize='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['Personal Loan'], df['Family'],normalize='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df['Personal Loan']==0]['Mortgage'],color='r',label=0)\n",
    "sns.distplot(df[df['Personal Loan']==1]['Mortgage'],color='g',label=1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Most people with zero motgage are not taking personal loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df[df['Personal Loan']==0]['Income'],color='r',label=0)\n",
    "sns.distplot(df[df['Personal Loan']==1]['Income'],color='g',label=1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of People with high income taking personal loan are high as compared to low income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df[df['Personal Loan']==0]['CCAvg'],color='r',label=0)\n",
    "sns.distplot(df[df['Personal Loan']==1]['CCAvg'],color='g',label=1)\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# People with high avg credit card spending per month are taking personal loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['CCAvg']==0].shape[0]\n",
    "\n",
    "#count of people having zero monthly spending on credit card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Family'] = df['Family'].astype('category')\n",
    "df['Education'] = df['Education'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Split the data into training and test set in the ratio of 70:30 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_Dad9_hNgHe"
   },
   "outputs": [],
   "source": [
    "# Separate the independent attributes i.e. every column except personal loan\n",
    "# Store the target column (Personal Loan) into Y array\n",
    "\n",
    "X = df.loc[:, df.columns != 'Personal Loan']  # independent variables\n",
    "\n",
    "y = df.loc[:, df.columns == 'Personal Loan']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and test data set in the ratio of 70:30 respectively. Can be of any ratio...\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=70)\n",
    "\n",
    "# Random state seeding for reapeatability of the code\n",
    "# if random state is not mentioned it would generate different train test sample in every run\n",
    "# test_size is to select the size of test data\n",
    "\n",
    "# two variables taken for split therefore output will generate 4 variables: test train for x and test train for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)  Training Logistic Regression model to predict the likelihood of a customer buying personal loans. Print all the metrics related for evaluating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing necessary metrics to evaluate model performance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_auc_score,roc_curve\n",
    "\n",
    "# Blanks list to store model name, training score, testing score, recall, precision and roc\n",
    "\n",
    "algo= []\n",
    "tr = []\n",
    "te = []\n",
    "recall = []\n",
    "precision = []\n",
    "roc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mn2mLl5GNgHn",
    "outputId": "e9ce8edf-088d-448f-c714-fdc51962ba7a"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=7)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class=model.predict(X_test)\n",
    "y_pred_prob=model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class[:5][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_prob[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_prob[:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_prob[:20,:]\n",
    "(y_pred_prob[:5,0]>0.5)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get confusion matrix in a proper format\n",
    "def draw_cm( actual, predicted ):\n",
    "    cm = confusion_matrix( actual, predicted)\n",
    "    sns.heatmap(cm, annot=True,  fmt='.0f', xticklabels = [0,1] , yticklabels = [0,1] )\n",
    "    plt.ylabel('Observed')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_cm(y_test,y_pred_class);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "95/(95+50) #recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "95/(95+22) #Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cm(y_test,y_pred_prob[:,1]>.7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "78/(78+67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "78/(78+6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix means**\n",
    "\n",
    "* True Positive (observed=1,predicted=1): Predicted Personal loan will be taken and the customer took it\n",
    "\n",
    "* False Positive (observed=0,predicted=1): Predicted Personal loan will be taken and the customer did not take it\n",
    "\n",
    "* True Negative (observed=0,predicted=0): Predicted Personal loan will not be taken and the customer did not take it\n",
    "\n",
    "* False Negative (observed=1,predicted=0): Predicted Personal loan will not be taken and the customer took it\n",
    "\n",
    "Here more focus towards should be towards recall because our target variable is 'Personal Loan' , i.e whether the customer is accepting the personal loan or not. And the bank wants more people to accept personal loan i.e. less number of False Negative, so that bank doesn't lose real customers who want to take loan. Hence the focus should be on increasing Recall.\n",
    "\n",
    "After achieving the desired accuracy we can deploy the model for practical use. As in the bank now can predict who will say yes for the personnel loan. They can use the model for upcoming customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_df=pd.DataFrame([fpr,tpr,thresholds]).T\n",
    "roc_df.columns=['fpr','tpr','thresholds']\n",
    "roc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Links & Addtional Material :\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "<b>Model Evaluation & Validation </b>\n",
    "\n",
    "* https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/\n",
    "* https://medium.com/analytics-vidhya/a-simple-introduction-to-validating-and-testing-a-model-part-1-2a0765deb198\n",
    "\n",
    "<b> Blogs on Same Data - </b>\n",
    "* https://medium.com/@rohanaggarwal45/thera-bank-case-with-univariate-as-well-as-bivariate-analysis-all-the-machine-learning-models-7f61d04eaa2a\n",
    "\n",
    "* https://www.kaggle.com/pritech/bank-personal-loan-modelling"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mini+Project+Bank+Loan_solution (1).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
