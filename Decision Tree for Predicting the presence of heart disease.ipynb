{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, pydotplus\n",
    "from sklearn import tree, metrics, model_selection, preprocessing\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('trainData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AHD']=df['AHD'].apply(lambda x : 1 if x=='Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['AHD'],_=pd.factorize(df['AHD'],sort=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder and initializing it\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(df['ChestPain'])\n",
    "df['ChestPain']=pd.Categorical(le.transform(df['ChestPain']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(df['Thal'])\n",
    "df['Thal']=pd.Categorical(le.transform(df['Thal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "y_train = df['AHD']\n",
    "X_train = df.iloc[:,0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the decision tree\n",
    "dtree = tree.DecisionTreeClassifier(criterion='gini')\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(dtree, \n",
    "                   feature_names=X_train.columns,  \n",
    "                   class_names=['0','1'],\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob = dtree.predict_proba(X_train)\n",
    "y_train_pred_class= y_train_pred_prob[:,1]>0.5\n",
    "pd.crosstab(y_train,y_train_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the decision tree\n",
    "dtree = tree.DecisionTreeClassifier(criterion='gini',min_samples_leaf=10,max_depth=3)\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(dtree, \n",
    "                   feature_names=X_train.columns,  \n",
    "                   class_names=['0','1'],\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob = dtree.predict_proba(X_train)\n",
    "y_train_pred_class= y_train_pred_prob[:,1]>0.5\n",
    "pd.crosstab(y_train,y_train_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(157+113)/(157+14+30+114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#y_train_pred_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_pred_prob[:5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = dtree.predict(X_train)\n",
    "y_train_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on Test Data Set\n",
    "# load the data\n",
    "df_test = pd.read_csv('testData.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['AHD']=df_test['AHD'].apply(lambda x : 1 if x=='Yes' else 0)\n",
    "#df_test['AHD'],_=pd.factorize(df_test['AHD'],sort=False)\n",
    "\n",
    "le.fit(df_test['ChestPain'])\n",
    "df_test['ChestPain']=pd.Categorical(le.transform(df_test['ChestPain']))\n",
    "\n",
    "le.fit(df_test['Thal'])\n",
    "df_test['Thal']=pd.Categorical(le.transform(df_test['Thal']))\n",
    "df_test=df_test.dropna()\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "y_test = df_test['AHD']\n",
    "X_test = df_test.iloc[:,0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_pred_prob = dtree.predict_proba(X_test)\n",
    "y_test_pred_prob[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_class = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(y_test,y_test_pred_prob[:,1]>0.5)\n",
    "pd.crosstab(y_test,y_test_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(64+51)/(14+64+51+8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice : Descision Tree excercise on IRIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the iris data\n",
    "df = pd.read_csv('iris.csv')\n",
    "df['species_label'], _ = pd.factorize(df['species'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "y = df['species_label']\n",
    "X = df[['petal_length', 'petal_width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data randomly into 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model and make predictions\n",
    "\n",
    "Note we didn't have to standardize the data to use a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the decision tree\n",
    "dtree = tree.DecisionTreeClassifier(criterion='gini',random_state=0)\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = dtree.predict_proba(X_test)\n",
    "y_pred_prob[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to make predictions with the test data\n",
    "y_pred = dtree.predict(X_test)\n",
    "y_pred[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model's performance\n",
    "\n",
    "Including the tree's axis-parallel decision boundaries and how the tree splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "43/45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "For visualizing decision tree splits I am creating **plot_decision()** function below using matplotlib. If you dont understand the implementation completely that's fine. It is just for the understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision(X, y, classifier, test_idx=None, resolution=0.02, figsize=(8,8)):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('#cc0000', '#003399', '#00cc00', '#999999', '#66ffff')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    \n",
    "    # get dimensions\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n",
    "    xmin = xx1.min()\n",
    "    xmax = xx1.max()\n",
    "    ymin = xx2.min()\n",
    "    ymax = xx2.max()\n",
    "    \n",
    "    # create the figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    \n",
    "    # plot the decision surface\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    ax.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap, zorder=1)\n",
    "    \n",
    "    # plot all samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        ax.scatter(x=X[y == cl, 0], \n",
    "                   y=X[y == cl, 1],\n",
    "                   alpha=0.6, \n",
    "                   c=cmap(idx),\n",
    "                   edgecolor='black',\n",
    "                   marker='o',#markers[idx],\n",
    "                   s=50,\n",
    "                   label=cl,\n",
    "                   zorder=3)\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "        ax.scatter(X_test[:, 0],\n",
    "                   X_test[:, 1],\n",
    "                   c='w',\n",
    "                   alpha=1.0,\n",
    "                   edgecolor='black',\n",
    "                   linewidths=1,\n",
    "                   marker='o',\n",
    "                   s=150, \n",
    "                   label='test set',\n",
    "                   zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model's decision regions to see how it separates the samples\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "plot_decision(X=X_combined, y=y_combined, classifier=dtree)\n",
    "plt.xlabel('petal length')\n",
    "plt.ylabel('petal width')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing, but this time identify the points that constituted the test data set\n",
    "test_idx = range(len(y_train), len(y_combined))\n",
    "plot_decision(X=X_combined, y=y_combined, classifier=dtree, test_idx=test_idx)\n",
    "plt.xlabel('petal length')\n",
    "plt.ylabel('petal width')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Decision Tree Algorithm Advantages and Disadvantages\n",
    "\n",
    "##### Advantages:\n",
    "\n",
    "   * Decision Trees are easy to explain. It results in a set of rules.\n",
    "   * It follows the same approach as humans generally follow while making decisions.\n",
    "   * Interpretation of a complex Decision Tree model can be simplified by its visualizations. Even a naive person can understand logic.\n",
    "   * The Number of hyper-parameters to be tuned is almost null.\n",
    "\n",
    "\n",
    "##### Disadvantages:\n",
    "\n",
    "   * There is a high probability of overfitting in Decision Tree.\n",
    "   * Generally, it gives low prediction accuracy for a dataset as compared to other machine learning algorithms.\n",
    "   * Information gain in a decision tree with categorical variables gives a biased response for attributes with greater no. of categories.\n",
    "   * Calculations can become complex when there are many class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree for Regression Problem- ie. when the target variable is continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "dataset = load_boston()\n",
    "X = dataset.data\n",
    "Y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(X)\n",
    "X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.DataFrame(Y)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=3, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "bag_tree = DecisionTreeRegressor(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_tree.fit(X_train, y_train)\n",
    "bag_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(bag_tree,feature_names=X_train.columns,filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Material\n",
    "* https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1\n",
    "\n",
    "* http://www.r2d3.us/visual-intro-to-machine-learning-part-1/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
